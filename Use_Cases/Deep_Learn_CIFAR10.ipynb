{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 12:48:27.982867: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(69)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, activation=\"swish\", kernel_initializer=\"he_normal\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this adds an output layer with 10 neurons (one per class) using the softmax activation function\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now want to use the Nadam optimizer with a learning rate of 5e-5\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now load the dataset that we want to use\n",
    "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar10_model/my_cifar10_model.h5\", save_best_only=True\n",
    ")\n",
    "run_index = 1  # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fea02369177bdf5d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fea02369177bdf5d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_cifar10_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 15s 6ms/step - loss: 4.0464 - accuracy: 0.1564 - val_loss: 2.2391 - val_accuracy: 0.2104\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.1019 - accuracy: 0.2281 - val_loss: 2.0120 - val_accuracy: 0.2622\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.9844 - accuracy: 0.2763 - val_loss: 1.9633 - val_accuracy: 0.2778\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8985 - accuracy: 0.3079 - val_loss: 1.8913 - val_accuracy: 0.3128\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.8340 - accuracy: 0.3347 - val_loss: 1.8385 - val_accuracy: 0.3328\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7864 - accuracy: 0.3508 - val_loss: 1.7798 - val_accuracy: 0.3516\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7385 - accuracy: 0.3727 - val_loss: 1.7421 - val_accuracy: 0.3744\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7049 - accuracy: 0.3818 - val_loss: 1.7144 - val_accuracy: 0.3728\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6705 - accuracy: 0.3964 - val_loss: 1.7043 - val_accuracy: 0.3722\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6424 - accuracy: 0.4064 - val_loss: 1.6443 - val_accuracy: 0.4066\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6207 - accuracy: 0.4129 - val_loss: 1.6650 - val_accuracy: 0.4036\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.6044 - accuracy: 0.4190 - val_loss: 1.6427 - val_accuracy: 0.3996\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5852 - accuracy: 0.4274 - val_loss: 1.6437 - val_accuracy: 0.3990\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5692 - accuracy: 0.4352 - val_loss: 1.6195 - val_accuracy: 0.4154\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5540 - accuracy: 0.4392 - val_loss: 1.6014 - val_accuracy: 0.4236\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5361 - accuracy: 0.4473 - val_loss: 1.5964 - val_accuracy: 0.4276\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5223 - accuracy: 0.4534 - val_loss: 1.5793 - val_accuracy: 0.4302\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5112 - accuracy: 0.4570 - val_loss: 1.6184 - val_accuracy: 0.4282\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4953 - accuracy: 0.4636 - val_loss: 1.5932 - val_accuracy: 0.4252\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4854 - accuracy: 0.4637 - val_loss: 1.5989 - val_accuracy: 0.4220\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4739 - accuracy: 0.4674 - val_loss: 1.6284 - val_accuracy: 0.4200\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4623 - accuracy: 0.4737 - val_loss: 1.5452 - val_accuracy: 0.4478\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4489 - accuracy: 0.4819 - val_loss: 1.5597 - val_accuracy: 0.4436\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4412 - accuracy: 0.4832 - val_loss: 1.5355 - val_accuracy: 0.4526\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4314 - accuracy: 0.4854 - val_loss: 1.5605 - val_accuracy: 0.4444\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4194 - accuracy: 0.4905 - val_loss: 1.5467 - val_accuracy: 0.4486\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4123 - accuracy: 0.4933 - val_loss: 1.5471 - val_accuracy: 0.4540\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4039 - accuracy: 0.4976 - val_loss: 1.5744 - val_accuracy: 0.4412\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3950 - accuracy: 0.4988 - val_loss: 1.5799 - val_accuracy: 0.4364\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3860 - accuracy: 0.5032 - val_loss: 1.5403 - val_accuracy: 0.4506\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3781 - accuracy: 0.5065 - val_loss: 1.5555 - val_accuracy: 0.4452\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3676 - accuracy: 0.5083 - val_loss: 1.5334 - val_accuracy: 0.4564\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3601 - accuracy: 0.5118 - val_loss: 1.5529 - val_accuracy: 0.4496\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3530 - accuracy: 0.5159 - val_loss: 1.5382 - val_accuracy: 0.4550\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3436 - accuracy: 0.5162 - val_loss: 1.5619 - val_accuracy: 0.4558\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3373 - accuracy: 0.5195 - val_loss: 1.5352 - val_accuracy: 0.4550\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3263 - accuracy: 0.5243 - val_loss: 1.6319 - val_accuracy: 0.4358\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3222 - accuracy: 0.5261 - val_loss: 1.5404 - val_accuracy: 0.4550\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3136 - accuracy: 0.5259 - val_loss: 1.5533 - val_accuracy: 0.4644\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3088 - accuracy: 0.5289 - val_loss: 1.5364 - val_accuracy: 0.4560\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.3007 - accuracy: 0.5350 - val_loss: 1.5931 - val_accuracy: 0.4438\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2915 - accuracy: 0.5357 - val_loss: 1.5369 - val_accuracy: 0.4568\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2846 - accuracy: 0.5393 - val_loss: 1.5375 - val_accuracy: 0.4626\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2759 - accuracy: 0.5386 - val_loss: 1.5557 - val_accuracy: 0.4634\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2713 - accuracy: 0.5437 - val_loss: 1.5554 - val_accuracy: 0.4590\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2629 - accuracy: 0.5454 - val_loss: 1.5959 - val_accuracy: 0.4464\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2582 - accuracy: 0.5473 - val_loss: 1.5892 - val_accuracy: 0.4442\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2488 - accuracy: 0.5512 - val_loss: 1.5743 - val_accuracy: 0.4574\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2425 - accuracy: 0.5546 - val_loss: 1.5911 - val_accuracy: 0.4620\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2380 - accuracy: 0.5558 - val_loss: 1.5598 - val_accuracy: 0.4582\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2266 - accuracy: 0.5620 - val_loss: 1.5715 - val_accuracy: 0.4538\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.2223 - accuracy: 0.5627 - val_loss: 1.5813 - val_accuracy: 0.4552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x132eeb890>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5334 - accuracy: 0.4564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.533409833908081, 0.4564000070095062]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 29s 10ms/step - loss: 2.0396 - accuracy: 0.2526 - val_loss: 2.0349 - val_accuracy: 0.2764\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7854 - accuracy: 0.3572 - val_loss: 2.0590 - val_accuracy: 0.2744\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.6879 - accuracy: 0.3945 - val_loss: 1.7345 - val_accuracy: 0.3646\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.6193 - accuracy: 0.4209 - val_loss: 1.7090 - val_accuracy: 0.3830\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5681 - accuracy: 0.4420 - val_loss: 1.6668 - val_accuracy: 0.4024\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5173 - accuracy: 0.4569 - val_loss: 1.7030 - val_accuracy: 0.3978\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4743 - accuracy: 0.4745 - val_loss: 1.6217 - val_accuracy: 0.4322\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4397 - accuracy: 0.4884 - val_loss: 1.7328 - val_accuracy: 0.3972\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4098 - accuracy: 0.5004 - val_loss: 1.5384 - val_accuracy: 0.4522\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3673 - accuracy: 0.5144 - val_loss: 1.6212 - val_accuracy: 0.4220\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3417 - accuracy: 0.5240 - val_loss: 1.5007 - val_accuracy: 0.4754\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3104 - accuracy: 0.5360 - val_loss: 1.5496 - val_accuracy: 0.4660\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2843 - accuracy: 0.5455 - val_loss: 1.5810 - val_accuracy: 0.4426\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2611 - accuracy: 0.5539 - val_loss: 1.5407 - val_accuracy: 0.4620\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2383 - accuracy: 0.5622 - val_loss: 1.5570 - val_accuracy: 0.4650\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2163 - accuracy: 0.5721 - val_loss: 1.5974 - val_accuracy: 0.4626\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1969 - accuracy: 0.5773 - val_loss: 1.6286 - val_accuracy: 0.4504\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1751 - accuracy: 0.5847 - val_loss: 1.5167 - val_accuracy: 0.4728\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1608 - accuracy: 0.5901 - val_loss: 1.5211 - val_accuracy: 0.4894\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1474 - accuracy: 0.5960 - val_loss: 1.5245 - val_accuracy: 0.4852\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1230 - accuracy: 0.6028 - val_loss: 1.5735 - val_accuracy: 0.4652\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1068 - accuracy: 0.6095 - val_loss: 1.5276 - val_accuracy: 0.4770\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0920 - accuracy: 0.6154 - val_loss: 1.5027 - val_accuracy: 0.4878\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0756 - accuracy: 0.6204 - val_loss: 1.5568 - val_accuracy: 0.4756\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0633 - accuracy: 0.6263 - val_loss: 1.7173 - val_accuracy: 0.4482\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0539 - accuracy: 0.6281 - val_loss: 1.5740 - val_accuracy: 0.4698\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0372 - accuracy: 0.6362 - val_loss: 1.5981 - val_accuracy: 0.4642\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0242 - accuracy: 0.6389 - val_loss: 1.5308 - val_accuracy: 0.4956\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0130 - accuracy: 0.6409 - val_loss: 1.5815 - val_accuracy: 0.4808\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9986 - accuracy: 0.6484 - val_loss: 1.6465 - val_accuracy: 0.4660\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9856 - accuracy: 0.6542 - val_loss: 1.6099 - val_accuracy: 0.4768\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.5007 - accuracy: 0.4754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5007493495941162, 0.47540000081062317]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to improve this using batch normalization to see if we can train faster and better\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(69)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(\"swish\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar10_model/my_cifar10_bn_model.h5\", save_best_only=True\n",
    ")\n",
    "run_index = 1  # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_bn_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 17s 7ms/step - loss: 1.9512 - accuracy: 0.2972 - val_loss: 1.8369 - val_accuracy: 0.3510\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7420 - accuracy: 0.3813 - val_loss: 1.6836 - val_accuracy: 0.4022\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6472 - accuracy: 0.4176 - val_loss: 1.6810 - val_accuracy: 0.4270\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5724 - accuracy: 0.4477 - val_loss: 1.6506 - val_accuracy: 0.4104\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5193 - accuracy: 0.4660 - val_loss: 1.5704 - val_accuracy: 0.4460\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4696 - accuracy: 0.4865 - val_loss: 1.5594 - val_accuracy: 0.4560\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4288 - accuracy: 0.5006 - val_loss: 1.5326 - val_accuracy: 0.4782\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3862 - accuracy: 0.5190 - val_loss: 1.5065 - val_accuracy: 0.4796\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3557 - accuracy: 0.5300 - val_loss: 1.4887 - val_accuracy: 0.4870\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3193 - accuracy: 0.5429 - val_loss: 1.5430 - val_accuracy: 0.4654\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2925 - accuracy: 0.5553 - val_loss: 1.5309 - val_accuracy: 0.4818\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2599 - accuracy: 0.5630 - val_loss: 1.4974 - val_accuracy: 0.4822\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2310 - accuracy: 0.5768 - val_loss: 1.4928 - val_accuracy: 0.4948\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2283 - accuracy: 0.5774 - val_loss: 1.5286 - val_accuracy: 0.4758\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1984 - accuracy: 0.5882 - val_loss: 1.4875 - val_accuracy: 0.4904\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1500 - accuracy: 0.6059 - val_loss: 1.4700 - val_accuracy: 0.5042\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1394 - accuracy: 0.6089 - val_loss: 1.5661 - val_accuracy: 0.5008\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1181 - accuracy: 0.6180 - val_loss: 1.5337 - val_accuracy: 0.5080\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1036 - accuracy: 0.6242 - val_loss: 1.4908 - val_accuracy: 0.5130\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0881 - accuracy: 0.6290 - val_loss: 1.5058 - val_accuracy: 0.5136\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0697 - accuracy: 0.6352 - val_loss: 1.5417 - val_accuracy: 0.5088\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0473 - accuracy: 0.6429 - val_loss: 1.5329 - val_accuracy: 0.5046\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0332 - accuracy: 0.6492 - val_loss: 1.5137 - val_accuracy: 0.5134\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0251 - accuracy: 0.6537 - val_loss: 1.5591 - val_accuracy: 0.4994\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0036 - accuracy: 0.6591 - val_loss: 1.5487 - val_accuracy: 0.5124\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9914 - accuracy: 0.6635 - val_loss: 1.5773 - val_accuracy: 0.5008\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9754 - accuracy: 0.6714 - val_loss: 1.6114 - val_accuracy: 0.5064\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3575 - accuracy: 0.6201 - val_loss: 1.6340 - val_accuracy: 0.4430\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2338 - accuracy: 0.5756 - val_loss: 1.5436 - val_accuracy: 0.4858\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1263 - accuracy: 0.6128 - val_loss: 1.5452 - val_accuracy: 0.5020\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0770 - accuracy: 0.6321 - val_loss: 1.5878 - val_accuracy: 0.4956\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0395 - accuracy: 0.6462 - val_loss: 1.5471 - val_accuracy: 0.5094\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0055 - accuracy: 0.6573 - val_loss: 1.6069 - val_accuracy: 0.5012\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9755 - accuracy: 0.6709 - val_loss: 1.5897 - val_accuracy: 0.5072\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9495 - accuracy: 0.6780 - val_loss: 1.6137 - val_accuracy: 0.5070\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 0.9327 - accuracy: 0.6825 - val_loss: 1.6462 - val_accuracy: 0.5036\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4700 - accuracy: 0.5042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.469991683959961, 0.5041999816894531]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we now want to use SELU activation function to see if we can train faster and better than before\n",
    "tf.random.set_seed(69)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar10_model/my_cifar10_selu_model.h5\", save_best_only=True\n",
    ")\n",
    "run_index = 1  # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_selu_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 16s 7ms/step - loss: 1.8883 - accuracy: 0.3300 - val_loss: 1.7629 - val_accuracy: 0.3750\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6697 - accuracy: 0.4120 - val_loss: 1.6205 - val_accuracy: 0.4404\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5795 - accuracy: 0.4456 - val_loss: 1.6522 - val_accuracy: 0.4392\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5191 - accuracy: 0.4692 - val_loss: 1.5598 - val_accuracy: 0.4534\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4690 - accuracy: 0.4868 - val_loss: 1.5695 - val_accuracy: 0.4714\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4212 - accuracy: 0.5060 - val_loss: 1.5577 - val_accuracy: 0.4780\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3725 - accuracy: 0.5199 - val_loss: 1.5424 - val_accuracy: 0.4812\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3377 - accuracy: 0.5380 - val_loss: 1.5490 - val_accuracy: 0.4886\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3019 - accuracy: 0.5511 - val_loss: 1.5391 - val_accuracy: 0.4914\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2693 - accuracy: 0.5595 - val_loss: 1.5975 - val_accuracy: 0.4796\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2406 - accuracy: 0.5689 - val_loss: 1.5756 - val_accuracy: 0.4976\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2055 - accuracy: 0.5850 - val_loss: 1.5105 - val_accuracy: 0.5002\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1829 - accuracy: 0.5929 - val_loss: 1.5347 - val_accuracy: 0.5070\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1501 - accuracy: 0.6007 - val_loss: 1.6273 - val_accuracy: 0.4972\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.1263 - accuracy: 0.6154 - val_loss: 1.5507 - val_accuracy: 0.5046\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1009 - accuracy: 0.6252 - val_loss: 1.5726 - val_accuracy: 0.4958\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0739 - accuracy: 0.6319 - val_loss: 1.6030 - val_accuracy: 0.5112\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0553 - accuracy: 0.6401 - val_loss: 1.6320 - val_accuracy: 0.5170\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0327 - accuracy: 0.6482 - val_loss: 1.7060 - val_accuracy: 0.5020\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0117 - accuracy: 0.6538 - val_loss: 1.6588 - val_accuracy: 0.5186\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9933 - accuracy: 0.6627 - val_loss: 1.6898 - val_accuracy: 0.5084\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9733 - accuracy: 0.6712 - val_loss: 1.7314 - val_accuracy: 0.5036\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9548 - accuracy: 0.6745 - val_loss: 1.6762 - val_accuracy: 0.5088\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9357 - accuracy: 0.6858 - val_loss: 1.7587 - val_accuracy: 0.5082\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9163 - accuracy: 0.6911 - val_loss: 1.7677 - val_accuracy: 0.5128\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.9005 - accuracy: 0.6974 - val_loss: 1.7620 - val_accuracy: 0.5152\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8899 - accuracy: 0.7003 - val_loss: 1.8200 - val_accuracy: 0.5056\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8693 - accuracy: 0.7078 - val_loss: 1.8708 - val_accuracy: 0.5054\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8555 - accuracy: 0.7124 - val_loss: 1.8219 - val_accuracy: 0.4912\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.8442 - accuracy: 0.7151 - val_loss: 1.8472 - val_accuracy: 0.5106\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 0.8207 - accuracy: 0.7239 - val_loss: 1.8396 - val_accuracy: 0.5080\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 0.8211 - accuracy: 0.7238 - val_loss: 1.8481 - val_accuracy: 0.5096\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5105 - accuracy: 0.5002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5105043649673462, 0.5001999735832214]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we now try the alpha dropout to see if we can train faster and better than before\n",
    "tf.random.set_seed(69)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar10_model/my_cifar10_alpha_dropout_model.h5\", save_best_only=True\n",
    ")\n",
    "run_index = 1  # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_alpha_dropout_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now try MC Dropout to see if we can train faster and better than before\n",
    "class MCAlphaDropout(tf.keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is identical to the one we just trained but with MCAlphaDropout instead of AlphaDropout\n",
    "mc_model = tf.keras.Sequential(\n",
    "    [\n",
    "        (\n",
    "            MCAlphaDropout(layer.rate)\n",
    "            if isinstance(layer, tf.keras.layers.AlphaDropout)\n",
    "            else layer\n",
    "        )\n",
    "        for layer in model.layers\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are utility functions to make predictions for the most likely class and for the class probabilities (using MC Dropout)\n",
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return Y_probas.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 2ms/step\n",
      "157/157 [==============================] - 0s 2ms/step\n",
      "157/157 [==============================] - 0s 2ms/step\n",
      "157/157 [==============================] - 0s 2ms/step\n",
      "157/157 [==============================] - 0s 2ms/step\n",
      "157/157 [==============================] - 0s 2ms/step\n",
      "157/157 [==============================] - 0s 2ms/step\n",
      "157/157 [==============================] - 0s 2ms/step\n",
      "157/157 [==============================] - 0s 2ms/step\n",
      "157/157 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5004"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this makes predictions for the validation set using MC Dropout and computes the accuracy\n",
    "tf.random.set_seed(69)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = (y_pred == y_valid[:, 0]).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are now going to train the model with 1cycle scheduling to see if it improves the training speed and accuracy\n",
    "tf.random.set_seed(69)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one cycle classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "K = tf.keras.backend\n",
    "\n",
    "\n",
    "class ExponentialLearningRate(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.sum_of_epoch_losses = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        mean_epoch_loss = logs[\"loss\"]  # the epoch's mean loss so far\n",
    "        new_sum_of_epoch_losses = mean_epoch_loss * (batch + 1)\n",
    "        batch_loss = new_sum_of_epoch_losses - self.sum_of_epoch_losses\n",
    "        self.sum_of_epoch_losses = new_sum_of_epoch_losses\n",
    "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
    "        self.losses.append(batch_loss)\n",
    "        K.set_value(\n",
    "            self.model.optimizer.learning_rate,\n",
    "            self.model.optimizer.learning_rate * self.factor,\n",
    "        )\n",
    "\n",
    "\n",
    "class OneCycleScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self, iterations, max_lr=1e-3, start_lr=None, last_iterations=None, last_lr=None\n",
    "    ):\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(self, iter1, iter2, lr1, lr2):\n",
    "        return (lr2 - lr1) * (self.iteration - iter1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(0, self.half_iteration, self.start_lr, self.max_lr)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(\n",
    "                self.half_iteration, 2 * self.half_iteration, self.max_lr, self.start_lr\n",
    "            )\n",
    "        else:\n",
    "            lr = self._interpolate(\n",
    "                2 * self.half_iteration, self.iterations, self.start_lr, self.last_lr\n",
    "            )\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr)\n",
    "\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=1e-4, max_rate=1):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = (max_rate / min_rate) ** (1 / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses, \"b\")\n",
    "    plt.gca().set_xscale(\"log\")\n",
    "    max_loss = losses[0] + min(losses)\n",
    "    plt.hlines(min(losses), min(rates), max(rates), color=\"k\")\n",
    "    plt.axis([min(rates), max(rates), 0, max_loss])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 5s 9ms/step - loss: nan - accuracy: 0.1824\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(\n",
    "    model, X_train_scaled, y_train, epochs=1, batch_size=batch_size\n",
    ")\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(69)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(100, kernel_initializer=\"lecun_normal\", activation=\"selu\")\n",
    "    )\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=2e-2)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "352/352 [==============================] - 5s 9ms/step - loss: 2.0634 - accuracy: 0.2882 - val_loss: 1.7610 - val_accuracy: 0.3760\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.7543 - accuracy: 0.3780 - val_loss: 1.6619 - val_accuracy: 0.4230\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.6198 - accuracy: 0.4280 - val_loss: 1.6560 - val_accuracy: 0.4236\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.5404 - accuracy: 0.4540 - val_loss: 1.7117 - val_accuracy: 0.4304\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.4977 - accuracy: 0.4699 - val_loss: 1.7762 - val_accuracy: 0.4112\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.4554 - accuracy: 0.4845 - val_loss: 1.5989 - val_accuracy: 0.4472\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.4199 - accuracy: 0.4948 - val_loss: 1.6201 - val_accuracy: 0.4582\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.3535 - accuracy: 0.5222 - val_loss: 1.6166 - val_accuracy: 0.4568\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.2747 - accuracy: 0.5462 - val_loss: 1.5224 - val_accuracy: 0.4720\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.2024 - accuracy: 0.5721 - val_loss: 1.5672 - val_accuracy: 0.4912\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.1336 - accuracy: 0.5962 - val_loss: 1.5188 - val_accuracy: 0.5062\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0668 - accuracy: 0.6194 - val_loss: 1.5344 - val_accuracy: 0.5142\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.9967 - accuracy: 0.6438 - val_loss: 1.5527 - val_accuracy: 0.5164\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.9318 - accuracy: 0.6664 - val_loss: 1.5824 - val_accuracy: 0.5190\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.8930 - accuracy: 0.6834 - val_loss: 1.5989 - val_accuracy: 0.5158\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "n_iterations = math.ceil(len(X_train_scaled) / batch_size) * n_epochs\n",
    "onecycle = OneCycleScheduler(n_iterations, max_lr=0.05)\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=[onecycle],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
